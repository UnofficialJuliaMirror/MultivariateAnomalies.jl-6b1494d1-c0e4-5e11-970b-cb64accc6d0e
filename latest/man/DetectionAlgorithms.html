<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>- · MultivariateAnomalies.jl documentation</title><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script></head><body><nav class="toc"><h1>MultivariateAnomalies.jl</h1><form class="search" action="../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../index.html">Home</a></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="FeatureExtraction.html">-</a></li><li class="current"><a class="toctext" href="DetectionAlgorithms.html">-</a><ul class="internal"><li><a class="toctext" href="#Detection-Algorithms-1">Detection Algorithms</a></li><li><a class="toctext" href="#High-Level-Functions-1">High Level Functions</a></li><li><a class="toctext" href="#Functions-1">Functions</a></li><li><a class="toctext" href="#Index-1">Index</a></li></ul></li><li><a class="toctext" href="AUC.html">-</a></li><li><a class="toctext" href="DistDensity.html">-</a></li><li><a class="toctext" href="Scores.html">-</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Manual</li><li><a href="DetectionAlgorithms.html">-</a></li></ul><a class="edit-page" href="https://github.com/milanflach/MultivariateAnomalies.jl/tree/b270345bf449208ff1a10ba0de78860ebef56239/docs/src/man/DetectionAlgorithms.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/></header><h2><a class="nav-anchor" id="Detection-Algorithms-1" href="#Detection-Algorithms-1">Detection Algorithms</a></h2><p>detect anomalies out of multivariate correlated data. </p><h2><a class="nav-anchor" id="High-Level-Functions-1" href="#High-Level-Functions-1">High Level Functions</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.getParameters" href="#MultivariateAnomalies.getParameters"><code>MultivariateAnomalies.getParameters</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">getParameters(algorithms::Array{ASCIIString,1} = [&quot;REC&quot;, &quot;KDE&quot;], training_data::AbstractArray{tp, 2} = [NaN NaN])</code></pre><p>return an object of type PARAMS, given the <code>algorithms</code> and some <code>training_data</code> as a matrix.</p><p><strong>Arguments</strong></p><ul><li><pre><code class="language-none">algorithms</code></pre>: Subset of <pre><code class="language-none">[&quot;REC&quot;, &quot;KDE&quot;, &quot;KNN_Gamma&quot;, &quot;KNN_Delta&quot;, &quot;SVDD&quot;, &quot;KNFST&quot;, &quot;T2&quot;]</code></pre></li><li><pre><code class="language-none">training_data</code></pre>: data for training the algorithms / for getting the Parameters.</li><li><pre><code class="language-none">dist::ASCIIString = &quot;Euclidean&quot;</code></pre></li><li><pre><code class="language-none">sigma_quantile::Float64 = 0.5</code></pre> (median): quantile of the distance matrix, used to compute the weighting parameter for the kernel matrix (<pre><code class="language-none">algorithms = [&quot;SVDD&quot;, &quot;KNFST&quot;, &quot;KDE&quot;]</code></pre>)</li><li><pre><code class="language-none">varepsilon_quantile</code></pre> = <pre><code class="language-none">sigma_quantile</code></pre> by default: quantile of the distance matrix to compute the radius of the hyperball in which the number of reccurences is counted (<pre><code class="language-none">algorihtms = [&quot;REC&quot;]</code></pre>)</li><li><pre><code class="language-none">k_perc::Float64 = 0.05</code></pre>: percentage of the first dimension of <pre><code class="language-none">training_data</code></pre> to estimmate the number of nearest neighbors (<pre><code class="language-none">algorithms = [&quot;KNN-Gamma&quot;, &quot;KNN_Delta&quot;]</code></pre>)</li><li><pre><code class="language-none">nu::Float64 = 0.2</code></pre>: use the maximal percentage of outliers for <pre><code class="language-none">algorithms = [&quot;SVDD&quot;]</code></pre></li><li><pre><code class="language-none">temp_excl::Int64 = 0</code></pre>. Exclude temporal adjacent points from beeing count as recurrences of k-nearest neighbors <pre><code class="language-none">algorithms = [&quot;REC&quot;, &quot;KNN-Gamma&quot;, &quot;KNN_Delta&quot;]</code></pre></li><li><pre><code class="language-none">ensemble_method = &quot;None&quot;</code></pre>: compute an ensemble of the used algorithms. Possible choices (given in <pre><code class="language-none">compute_ensemble()</code></pre>) are &quot;mean&quot;, &quot;median&quot;, &quot;max&quot; and &quot;min&quot;.</li><li><pre><code class="language-none">quantiles = false</code></pre>: convert the output scores of the algorithms into quantiles.</li></ul><p><strong>Examples</strong></p><pre><code class="language-jlcon">julia&gt; training_data = randn(100, 2); testing_data = randn(100, 2);
julia&gt; P = getParameters([&quot;REC&quot;, &quot;KDE&quot;, &quot;SVDD&quot;], training_data, quantiles = false);
julia&gt; detectAnomalies(testing_data, P)</code></pre></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.detectAnomalies" href="#MultivariateAnomalies.detectAnomalies"><code>MultivariateAnomalies.detectAnomalies</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">detectAnomalies{tp, N}(data::AbstractArray{tp, N}, P::PARAMS)
detectAnomalies{tp, N}(data::AbstractArray{tp, N}, algorithms::Array{ASCIIString,1} = [&quot;REC&quot;, &quot;KDE&quot;]; mean = 0)</code></pre><p>detect anomalies, given some Parameter object <code>P</code> of type PARAMS. Train the Parameters <code>P</code> with <code>getParameters()</code> beforehand on some training data. See <code>getParameters()</code>. Without training <code>P</code> beforehand, it is also possible to use <code>detectAnomalies(data, algorithms)</code> given some algorithms (except SVDD, KNFST). Some default parameters are used in this case to initialize <code>P</code> internally.</p><p><strong>Examples</strong></p><pre><code class="language-jlcon">julia&gt; training_data = randn(100, 2); testing_data = randn(100, 2);
julia&gt; # compute the anoamly scores of the algorithms &quot;REC&quot;, &quot;KDE&quot;, &quot;T2&quot; and &quot;KNN_Gamma&quot;, their quantiles and return their ensemble scores
julia&gt; P = getParameters([&quot;REC&quot;, &quot;KDE&quot;, &quot;T2&quot;, &quot;KNN_Gamma&quot;], training_data, quantiles = true, ensemble_method = &quot;mean&quot;);
julia&gt; detectAnomalies(testing_data, P)</code></pre></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.detectAnomalies!" href="#MultivariateAnomalies.detectAnomalies!"><code>MultivariateAnomalies.detectAnomalies!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">detectAnomalies!{tp, N}(data::AbstractArray{tp, N}, P::PARAMS)</code></pre><p>mutating version of <code>detectAnomalies()</code>. Directly writes the output into <code>P</code>.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.init_detectAnomalies" href="#MultivariateAnomalies.init_detectAnomalies"><code>MultivariateAnomalies.init_detectAnomalies</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">init_detectAnomalies{tp, N}(data::AbstractArray{tp, N}, P::PARAMS)</code></pre><p>initialize empty arrays in <code>P</code> for detecting the anomalies.</p></div></section><h2><a class="nav-anchor" id="Functions-1" href="#Functions-1">Functions</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.REC" href="#MultivariateAnomalies.REC"><code>MultivariateAnomalies.REC</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">REC(D::AbstractArray, rec_threshold::Float64, temp_excl::Int = 5)</code></pre><p>Count the number of observations (recurrences) which fall into a radius <code>rec_threshold</code> of a distance matrix <code>D</code>. Exclude steps which are closer than <code>temp_excl</code> to be count as recurrences (default: <code>temp_excl = 5</code>)</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.REC!" href="#MultivariateAnomalies.REC!"><code>MultivariateAnomalies.REC!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">REC!(rec_out::AbstractArray, D::AbstractArray, rec_threshold::Float64, temp_excl::Int = 5)</code></pre><p>Memory efficient version of <code>REC()</code> for use within a loop. rec_out is preallocated output, should be initialised with <code>init_REC()</code>.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.init_REC" href="#MultivariateAnomalies.init_REC"><code>MultivariateAnomalies.init_REC</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">init_REC(D::Array{Float64, 2})
init_REC(T::Int)</code></pre><p>get object for memory efficient <code>REC!()</code> versions. Input can be a distance matrix <code>D</code> or the number of timesteps (observations) <code>T</code>.</p><p>Marwan, N., Carmen Romano, M., Thiel, M., &amp; Kurths, J. (2007). Recurrence plots for the analysis of complex systems. Physics Reports, 438(5-6), 237–329. http://doi.org/10.1016/j.physrep.2006.11.001</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.KDE" href="#MultivariateAnomalies.KDE"><code>MultivariateAnomalies.KDE</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">KDE(K)</code></pre><p>Compute a Kernel Density Estimation (the Parzen sum), given a Kernel matrix <code>K</code>.</p><p>Parzen, E. (1962). On Estimation of a Probability Density Function and Mode. The Annals of Mathematical Statistics, 33, 1–1065–1076.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.KDE!" href="#MultivariateAnomalies.KDE!"><code>MultivariateAnomalies.KDE!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">KDE!(KDE_out, K)</code></pre><p>Memory efficient version of <code>KDE()</code>. Additionally uses preallocated <code>KDE_out</code> object for writing the results. Initialize <code>KDE_out</code> with <code>init_KDE()</code>.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.init_KDE" href="#MultivariateAnomalies.init_KDE"><code>MultivariateAnomalies.init_KDE</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">init_KDE(K::Array{Float64, 2})
init_KDE(T::Int)</code></pre><p>Returns <code>KDE_out</code> object for usage in <code>KDE!()</code>. Use either a Kernel matrix <code>K</code> or the number of time steps/observations <code>T</code> as argument.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.T2" href="#MultivariateAnomalies.T2"><code>MultivariateAnomalies.T2</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">T2{tp}(data::AbstractArray{tp,2}, Q::AbstractArray[, mv])</code></pre><p>Compute Hotelling&#39;s T^2 control chart (the squared Mahalanobis distance to the data&#39;s mean vector (<code>mv</code>), given the covariance matrix <code>Q</code>). Input data is a two dimensional data matrix (observations * variables).</p><p>Lowry, C. A., &amp; Woodall, W. H. (1992). A Multivariate Exponentially Weighted Moving Average Control Chart. Technometrics, 34, 46–53.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.T2!" href="#MultivariateAnomalies.T2!"><code>MultivariateAnomalies.T2!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">T2!(t2_out, data, Q[, mv])</code></pre><p>Memory efficient version of <code>T2()</code>, for usage within a loop etc. Initialize the <code>t2_out</code> object with <code>init_T2()</code>. <code>t2_out[1]</code> contains the squred Mahalanobis distance after computation.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.init_T2" href="#MultivariateAnomalies.init_T2"><code>MultivariateAnomalies.init_T2</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">init_T2(VAR::Int, T::Int)
init_T2{tp}(data::AbstractArray{tp,2})</code></pre><p>initialize <code>t2_out</code> object for <code>T2!</code> either with number of variables <code>VAR</code> and observations/time steps <code>T</code> or with a two dimensional <code>data</code> matrix (time * variables)</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.KNN_Gamma" href="#MultivariateAnomalies.KNN_Gamma"><code>MultivariateAnomalies.KNN_Gamma</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">KNN_Gamma(knn_dists_out)</code></pre><p>This function computes the mean distance of the K nearest neighbors given a <code>knn_dists_out</code> object from <code>knn_dists()</code> as input argument.</p><p>Harmeling, S., Dornhege, G., Tax, D., Meinecke, F., &amp; Müller, K.-R. (2006). From outliers to prototypes: Ordering data. Neurocomputing, 69(13-15), 1608–1618. http://doi.org/10.1016/j.neucom.2005.05.015</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.KNN_Gamma!" href="#MultivariateAnomalies.KNN_Gamma!"><code>MultivariateAnomalies.KNN_Gamma!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">KNN_Gamma!(KNN_Gamma_out, knn_dists_out)</code></pre><p>Memory efficient version of <code>KNN_Gamma</code>, to be used in a loop. Initialize <code>KNN_Gamma_out</code> with <code>init_KNN_Gamma()</code>.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.init_KNN_Gamma" href="#MultivariateAnomalies.init_KNN_Gamma"><code>MultivariateAnomalies.init_KNN_Gamma</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">init_KNN_Gamma(T::Int)
init_KNN_Gamma(knn_dists_out)</code></pre><p>initialize a <code>KNN_Gamma_out</code> object for <code>KNN_Gamma!</code> either with <code>T</code>, the number of observations/time steps or with a <code>knn_dists_out</code> object.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.KNN_Delta" href="#MultivariateAnomalies.KNN_Delta"><code>MultivariateAnomalies.KNN_Delta</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">KNN_Delta(knn_dists_out, data)</code></pre><p>Compute Delta as vector difference of the k-nearest neighbors. Arguments are a <code>knn_dists()</code> object (<code>knn_dists_out</code>) and a <code>data</code> matrix (observations * variables)</p><p>Harmeling, S., Dornhege, G., Tax, D., Meinecke, F., &amp; Müller, K.-R. (2006). From outliers to prototypes: Ordering data. Neurocomputing, 69(13-15), 1608–1618. http://doi.org/10.1016/j.neucom.2005.05.015</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.KNN_Delta!" href="#MultivariateAnomalies.KNN_Delta!"><code>MultivariateAnomalies.KNN_Delta!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">KNN_Delta!(KNN_Delta_out, knn_dists_out, data)</code></pre><p>Memory Efficient Version of <code>KNN_Delta()</code>. <code>KNN_Delta_out[1]</code> is the vector difference of the k-nearest neighbors.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.init_KNN_Delta" href="#MultivariateAnomalies.init_KNN_Delta"><code>MultivariateAnomalies.init_KNN_Delta</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">init_KNN_Delta(T, VAR, k)</code></pre><p>return a <code>KNN_Delta_out</code> object to be used for <code>KNN_Delta!</code>. Input: time steps/observations <code>T</code>, variables <code>VAR</code>, number of K nearest neighbors <code>k</code>.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.UNIV" href="#MultivariateAnomalies.UNIV"><code>MultivariateAnomalies.UNIV</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">UNIV(data)</code></pre><p>order the values in each varaible and return their maximum, i.e. any of the variables in <code>data</code> (observations * variables) is above a given quantile, the highest quantile will be returned.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.UNIV!" href="#MultivariateAnomalies.UNIV!"><code>MultivariateAnomalies.UNIV!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">UNIV!(univ_out, data)</code></pre><p>Memory efficient version of <code>UNIV()</code>, input an <code>univ_out</code> object from <code>init_UNIV()</code> and some <code>data</code> matrix observations * variables</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.init_UNIV" href="#MultivariateAnomalies.init_UNIV"><code>MultivariateAnomalies.init_UNIV</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">init_UNIV(T::Int, VAR::Int)
init_UNIV{tp}(data::AbstractArray{tp, 2})</code></pre><p>initialize a <code>univ_out</code> object to be used in <code>UNIV!()</code> either with number of time steps/observations <code>T</code> and variables <code>VAR</code> or with a <code>data</code> matrix observations * variables.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.SVDD_train" href="#MultivariateAnomalies.SVDD_train"><code>MultivariateAnomalies.SVDD_train</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">SVDD_train(K, nu)</code></pre><p>train a one class support vecort machine model (i.e. support vector data description), given a kernel matrix K and and the highest possible percentage of outliers <code>nu</code>. Returns the model object (<code>svdd_model</code>). Requires LIBSVM.</p><p>Tax, D. M. J., &amp; Duin, R. P. W. (1999). Support vector domain description. Pattern Recognition Letters, 20, 1191–1199. Schölkopf, B., Williamson, R. C., &amp; Bartlett, P. L. (2000). New Support Vector Algorithms. Neural Computation, 12, 1207–1245.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.SVDD_predict" href="#MultivariateAnomalies.SVDD_predict"><code>MultivariateAnomalies.SVDD_predict</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">SVDD_predict(svdd_model, K)</code></pre><p>predict the outlierness of an object given the testing Kernel matrix <code>K</code> and the <code>svdd_model</code> from SVDD_train(). Requires LIBSVM.</p><p>Tax, D. M. J., &amp; Duin, R. P. W. (1999). Support vector domain description. Pattern Recognition Letters, 20, 1191–1199. Schölkopf, B., Williamson, R. C., &amp; Bartlett, P. L. (2000). New Support Vector Algorithms. Neural Computation, 12, 1207–1245.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.SVDD_predict!" href="#MultivariateAnomalies.SVDD_predict!"><code>MultivariateAnomalies.SVDD_predict!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">SVDD_predict!(SVDD_out, svdd_model, K)</code></pre><p>Memory efficient version of <code>SVDD_predict()</code>. Additional input argument is the <code>SVDD_out</code> object from <code>init_SVDD_predict()</code>. Compute <code>K</code>with <code>kernel_matrix()</code>. <code>SVDD_out[1]</code> are predicted labels, <code>SVDD_out[2]</code> decision_values. Requires LIBSVM.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.init_SVDD_predict" href="#MultivariateAnomalies.init_SVDD_predict"><code>MultivariateAnomalies.init_SVDD_predict</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">init_SVDD_predict(T::Int)
init_SVDD_predict(T::Int, Ttrain::Int)</code></pre><p>initializes a <code>SVDD_out</code> object to be used in <code>SVDD_predict!()</code>. Input is the number of time steps <code>T</code> (in prediction mode). If <code>T</code> for prediction differs from T of the training data (<code>Ttrain</code>) use <code>Ttrain</code> as additional argument.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.KNFST_train" href="#MultivariateAnomalies.KNFST_train"><code>MultivariateAnomalies.KNFST_train</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">KNFST_train(K)</code></pre><p>train a one class novelty KNFST model on a Kernel matrix <code>K</code> according to Paul Bodesheim and Alexander Freytag and Erik Rodner and Michael Kemmler and Joachim Denzler: &quot;Kernel Null Space Methods for Novelty Detection&quot;. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013.</p><p><strong>Output</strong></p><p><code>(proj, targetValue)</code> <code>proj</code> 	– projection vector for data points (project x via kx*proj, where kx is row vector containing kernel values of x and training data) <code>targetValue</code> – value of all training samples in the null space</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.KNFST_predict" href="#MultivariateAnomalies.KNFST_predict"><code>MultivariateAnomalies.KNFST_predict</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">KNFST_predict(model, K)</code></pre><p>predict the outlierness of some data (represented by the kernel matrix <code>K</code>), given some KNFST <code>model</code> from <code>KNFST_train(K)</code>. Compute <code>K</code>with <code>kernel_matrix()</code>.</p><p>Paul Bodesheim and Alexander Freytag and Erik Rodner and Michael Kemmler and Joachim Denzler: &quot;Kernel Null Space Methods for Novelty Detection&quot;. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.KNFST_predict!" href="#MultivariateAnomalies.KNFST_predict!"><code>MultivariateAnomalies.KNFST_predict!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">KNFST_predict!(KNFST_out, KNFST_mod, K)</code></pre><p>predict the outlierness of some data (represented by the kernel matrix <code>K</code>), given a <code>KNFST_out</code> object (<code>init_KNFST()</code>), some KNFST model (<code>KNFST_mod = KNFST_train(K)</code>) and the testing kernel matrix K.</p><p>Paul Bodesheim and Alexander Freytag and Erik Rodner and Michael Kemmler and Joachim Denzler: &quot;Kernel Null Space Methods for Novelty Detection&quot;. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MultivariateAnomalies.init_KNFST" href="#MultivariateAnomalies.init_KNFST"><code>MultivariateAnomalies.init_KNFST</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">init_KNFST(T, KNFST_mod)</code></pre><p>initialize a <code>KNFST_out</code>object for the use with <code>KNFST_predict!</code>, given <code>T</code>, the number of observations and the model output <code>KNFST_train(K)</code>.</p></div></section><h2><a class="nav-anchor" id="Index-1" href="#Index-1">Index</a></h2><ul><li><a href="FeatureExtraction.html#MultivariateAnomalies.EWMA"><code>MultivariateAnomalies.EWMA</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.EWMA!"><code>MultivariateAnomalies.EWMA!</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.KDE"><code>MultivariateAnomalies.KDE</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.KDE!"><code>MultivariateAnomalies.KDE!</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.KNFST_predict"><code>MultivariateAnomalies.KNFST_predict</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.KNFST_predict!"><code>MultivariateAnomalies.KNFST_predict!</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.KNFST_train"><code>MultivariateAnomalies.KNFST_train</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.KNN_Delta"><code>MultivariateAnomalies.KNN_Delta</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.KNN_Delta!"><code>MultivariateAnomalies.KNN_Delta!</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.KNN_Gamma"><code>MultivariateAnomalies.KNN_Gamma</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.KNN_Gamma!"><code>MultivariateAnomalies.KNN_Gamma!</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.REC"><code>MultivariateAnomalies.REC</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.REC!"><code>MultivariateAnomalies.REC!</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.SVDD_predict"><code>MultivariateAnomalies.SVDD_predict</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.SVDD_predict!"><code>MultivariateAnomalies.SVDD_predict!</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.SVDD_train"><code>MultivariateAnomalies.SVDD_train</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.T2"><code>MultivariateAnomalies.T2</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.T2!"><code>MultivariateAnomalies.T2!</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.TDE"><code>MultivariateAnomalies.TDE</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.UNIV"><code>MultivariateAnomalies.UNIV</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.UNIV!"><code>MultivariateAnomalies.UNIV!</code></a></li><li><a href="AUC.html#MultivariateAnomalies.auc"><code>MultivariateAnomalies.auc</code></a></li><li><a href="AUC.html#MultivariateAnomalies.auc_fpr_tpr"><code>MultivariateAnomalies.auc_fpr_tpr</code></a></li><li><a href="AUC.html#MultivariateAnomalies.boolevents"><code>MultivariateAnomalies.boolevents</code></a></li><li><a href="Scores.html#MultivariateAnomalies.compute_ensemble"><code>MultivariateAnomalies.compute_ensemble</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.detectAnomalies"><code>MultivariateAnomalies.detectAnomalies</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.detectAnomalies!"><code>MultivariateAnomalies.detectAnomalies!</code></a></li><li><a href="DistDensity.html#MultivariateAnomalies.dist_matrix"><code>MultivariateAnomalies.dist_matrix</code></a></li><li><a href="DistDensity.html#MultivariateAnomalies.dist_matrix!"><code>MultivariateAnomalies.dist_matrix!</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.getParameters"><code>MultivariateAnomalies.getParameters</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.get_MedianCycle"><code>MultivariateAnomalies.get_MedianCycle</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.get_MedianCycle!"><code>MultivariateAnomalies.get_MedianCycle!</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.get_MedianCycles"><code>MultivariateAnomalies.get_MedianCycles</code></a></li><li><a href="Scores.html#MultivariateAnomalies.get_quantile_scores"><code>MultivariateAnomalies.get_quantile_scores</code></a></li><li><a href="Scores.html#MultivariateAnomalies.get_quantile_scores!"><code>MultivariateAnomalies.get_quantile_scores!</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.globalICA"><code>MultivariateAnomalies.globalICA</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.globalPCA"><code>MultivariateAnomalies.globalPCA</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.init_KDE"><code>MultivariateAnomalies.init_KDE</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.init_KNFST"><code>MultivariateAnomalies.init_KNFST</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.init_KNN_Delta"><code>MultivariateAnomalies.init_KNN_Delta</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.init_KNN_Gamma"><code>MultivariateAnomalies.init_KNN_Gamma</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.init_MedianCycle"><code>MultivariateAnomalies.init_MedianCycle</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.init_REC"><code>MultivariateAnomalies.init_REC</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.init_SVDD_predict"><code>MultivariateAnomalies.init_SVDD_predict</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.init_T2"><code>MultivariateAnomalies.init_T2</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.init_UNIV"><code>MultivariateAnomalies.init_UNIV</code></a></li><li><a href="DetectionAlgorithms.html#MultivariateAnomalies.init_detectAnomalies"><code>MultivariateAnomalies.init_detectAnomalies</code></a></li><li><a href="DistDensity.html#MultivariateAnomalies.init_dist_matrix"><code>MultivariateAnomalies.init_dist_matrix</code></a></li><li><a href="DistDensity.html#MultivariateAnomalies.init_knn_dists"><code>MultivariateAnomalies.init_knn_dists</code></a></li><li><a href="DistDensity.html#MultivariateAnomalies.kernel_matrix"><code>MultivariateAnomalies.kernel_matrix</code></a></li><li><a href="DistDensity.html#MultivariateAnomalies.kernel_matrix!"><code>MultivariateAnomalies.kernel_matrix!</code></a></li><li><a href="DistDensity.html#MultivariateAnomalies.knn_dists"><code>MultivariateAnomalies.knn_dists</code></a></li><li><a href="DistDensity.html#MultivariateAnomalies.knn_dists!"><code>MultivariateAnomalies.knn_dists!</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.mw_COR"><code>MultivariateAnomalies.mw_COR</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.mw_VAR"><code>MultivariateAnomalies.mw_VAR</code></a></li><li><a href="FeatureExtraction.html#MultivariateAnomalies.sMSC"><code>MultivariateAnomalies.sMSC</code></a></li></ul><footer><hr/><a class="previous" href="FeatureExtraction.html"><span class="direction">Previous</span><span class="title">-</span></a><a class="next" href="AUC.html"><span class="direction">Next</span><span class="title">-</span></a></footer></article></body></html>
